{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dc1ec35",
   "metadata": {},
   "source": [
    "**Problem Statement: Build a sentiment analysis on twitter dataset using any deep learning technique.**\n",
    "\n",
    "Dataset: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
    "\n",
    "**About Dataset**\n",
    "\n",
    "**Context**\n",
    "\n",
    "This is the sentiment140 dataset. It contains 1,600,000 tweets extracted using the twitter api . The tweets have been annotated (0 = negative, 4 = positive) and they can be used to detect sentiment .\n",
    "\n",
    "**Content**\n",
    "It contains the following 6 fields:\n",
    "\n",
    "1. target: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "\n",
    "2. ids: The id of the tweet ( 2087)\n",
    "\n",
    "3. date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "\n",
    "4. flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "\n",
    "5. user: the user that tweeted (robotickilldozr)\n",
    "\n",
    "6. text: the text of the tweet (Lyx is cool)\n",
    "\n",
    "**Acknowledgements**\n",
    "\n",
    "The official link regarding the dataset with resources about how it was generated is here\n",
    "The official paper detailing the approach is here\n",
    "\n",
    "Citation: Go, A., Bhayani, R. and Huang, L., 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford, 1(2009), p.12."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960b60a2",
   "metadata": {},
   "source": [
    "## Loading and Visualisation\n",
    "First let us import the dataset stored in the computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5efa72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "df = pd.read_csv(\"C://Users//pavan//STARAGILE//sentiment twitter analysis.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea26d12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY _TheSpecialOne_  \\\n",
       "0  0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   scotthamilton   \n",
       "1  0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY        mattycus   \n",
       "2  0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         ElleCTF   \n",
       "3  0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          Karoli   \n",
       "4  0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY        joy_wolf   \n",
       "\n",
       "  @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0  is upset that he can't update his Facebook by ...                                                                   \n",
       "1  @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2    my whole body feels itchy and like its on fire                                                                    \n",
       "3  @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                      @Kwesidei not the whole crew                                                                    "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a339dcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names (replace with your own column names)\n",
    "column_names = [\"target\", \"ids\", \"date\",\"flag\",\"user\",\"text\"]  # Provide the appropriate column names\n",
    "\n",
    "# Assign the column names to the DataFrame\n",
    "df.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d462b173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag           user  \\\n",
       "0       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY  scotthamilton   \n",
       "1       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY       mattycus   \n",
       "2       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY        ElleCTF   \n",
       "3       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY         Karoli   \n",
       "4       0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY       joy_wolf   \n",
       "\n",
       "                                                text  \n",
       "0  is upset that he can't update his Facebook by ...  \n",
       "1  @Kenichan I dived many times for the ball. Man...  \n",
       "2    my whole body feels itchy and like its on fire   \n",
       "3  @nationwideclass no, it's not behaving at all....  \n",
       "4                      @Kwesidei not the whole crew   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa249dbd",
   "metadata": {},
   "source": [
    "Lets only keep 'target' and 'text' columns for our analysis as other columns are irrelevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a7678d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  is upset that he can't update his Facebook by ...\n",
       "1       0  @Kenichan I dived many times for the ball. Man...\n",
       "2       0    my whole body feels itchy and like its on fire \n",
       "3       0  @nationwideclass no, it's not behaving at all....\n",
       "4       0                      @Kwesidei not the whole crew "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the \"target\" and \"text\" columns\n",
    "df = df[[\"target\", \"text\"]]\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7c30e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599999 entries, 0 to 1599998\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count    Dtype \n",
      "---  ------  --------------    ----- \n",
      " 0   target  1599999 non-null  int64 \n",
      " 1   text    1599999 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa6c0b",
   "metadata": {},
   "source": [
    "\n",
    "The DataFrame has a shape of (1599999 rows, 2 columns). Here's a breakdown of the columns and some additional information:\n",
    "\n",
    ">Column 0 (target): Contains integer values representing the sentiment polarity (0 for negative, 2 for neutral, and 4 for positive).\n",
    "\n",
    ">Column 1 (text): Contains the text content of the tweets as objects (string data type).\n",
    "\n",
    ">There are no missing values (non-null count is the same as the total number of entries).\n",
    "\n",
    ">The \"target\" column is of type int64, while the \"text\" column is of type object (string).\n",
    "\n",
    ">The memory usage of the DataFrame is approximately 24.4+ MB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a197f",
   "metadata": {},
   "source": [
    "Check the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "049ed74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (1599999, 2)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the DataFrame\n",
    "shape = df.shape\n",
    "\n",
    "# Display the shape\n",
    "print(\"Shape of the DataFrame:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b638744e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count the number of positive (4) and negative (0) reviews\n",
    "sentiment_counts = df['target'].value_counts()\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=sentiment_counts.index, y=sentiment_counts.values, palette=\"Set2\")\n",
    "plt.title('Distribution of Positive and Negative Reviews')\n",
    "plt.xlabel('Sentiment Label')\n",
    "plt.ylabel('Number of Reviews')\n",
    "plt.xticks([0, 1], ['Negative (0)', 'Positive (4)'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b048c5",
   "metadata": {},
   "source": [
    "The above graph shows the reviews in twitter handles which has equal number of positive and negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17ee967",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001abc9b",
   "metadata": {},
   "source": [
    "In this steps initially we will remove all the punctuation marks and all the urls, digits, numbers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2910acd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, Faceb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[Kenichan, I, dived, many, times, for, the, ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>[Kwesidei, not, the, whole, crew]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  is upset that he can't update his Facebook by ...   \n",
       "1  @Kenichan I dived many times for the ball. Man...   \n",
       "2    my whole body feels itchy and like its on fire    \n",
       "3  @nationwideclass no, it's not behaving at all....   \n",
       "4                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                      processed_text  \n",
       "0  [is, upset, that, he, cant, update, his, Faceb...  \n",
       "1  [Kenichan, I, dived, many, times, for, the, ba...  \n",
       "2  [my, whole, body, feels, itchy, and, like, its...  \n",
       "3  [nationwideclass, no, its, not, behaving, at, ...  \n",
       "4                  [Kwesidei, not, the, whole, crew]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# Function to remove punctuation and split text into words\n",
    "def process_text(text):\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove newlines and split into words\n",
    "    words = text.replace('\\n', ' ').split()\n",
    "    return words\n",
    "\n",
    "# Apply the process_text function to the \"text\" column of your DataFrame\n",
    "df['processed_text'] = df['text'].apply(process_text)\n",
    "\n",
    "# Display the first few rows of the DataFrame with processed text\n",
    "df[['text', 'processed_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4357b881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[is, upset, that, he, cant, update, his, Faceb...</td>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Kenichan, I, dived, many, times, for, the, ba...</td>\n",
       "      <td>Kenichan I dived many times for the ball Manag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Kwesidei, not, the, whole, crew]</td>\n",
       "      <td>Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      processed_text  \\\n",
       "0  [is, upset, that, he, cant, update, his, Faceb...   \n",
       "1  [Kenichan, I, dived, many, times, for, the, ba...   \n",
       "2  [my, whole, body, feels, itchy, and, like, its...   \n",
       "3  [nationwideclass, no, its, not, behaving, at, ...   \n",
       "4                  [Kwesidei, not, the, whole, crew]   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  is upset that he cant update his Facebook by t...  \n",
       "1  Kenichan I dived many times for the ball Manag...  \n",
       "2     my whole body feels itchy and like its on fire  \n",
       "3  nationwideclass no its not behaving at all im ...  \n",
       "4                        Kwesidei not the whole crew  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to remove web addresses, Twitter IDs, and digits from text\n",
    "def remove_patterns(words):\n",
    "    # Join the list of words into a single string\n",
    "    text = ' '.join(words)\n",
    "    # Remove web addresses (URLs)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove Twitter IDs (mentions)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove digits\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the remove_patterns function to the \"processed_text\" column\n",
    "df['cleaned_text'] = df['processed_text'].apply(remove_patterns)\n",
    "\n",
    "# Display the first few rows of the DataFrame with cleaned text\n",
    "df[['processed_text', 'cleaned_text']].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2193d",
   "metadata": {},
   "source": [
    "Now all the data has been cleaned. We will next convert the text data to encoded data by tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69f97a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>encoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "      <td>[169960, 496697, 385662, 748809, 277102, 50188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenichan I dived many times for the ball Manag...</td>\n",
       "      <td>[465336, 850475, 629033, 513059, 8598, 601250,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[842064, 399001, 365467, 536171, 508846, 17586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[75233, 565059, 783986, 278229, 358302, 105038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kwesidei not the whole crew</td>\n",
       "      <td>[272903, 278229, 405433, 399001, 494318]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_text  \\\n",
       "0  is upset that he cant update his Facebook by t...   \n",
       "1  Kenichan I dived many times for the ball Manag...   \n",
       "2     my whole body feels itchy and like its on fire   \n",
       "3  nationwideclass no its not behaving at all im ...   \n",
       "4                        Kwesidei not the whole crew   \n",
       "\n",
       "                                        encoded_text  \n",
       "0  [169960, 496697, 385662, 748809, 277102, 50188...  \n",
       "1  [465336, 850475, 629033, 513059, 8598, 601250,...  \n",
       "2  [842064, 399001, 365467, 536171, 508846, 17586...  \n",
       "3  [75233, 565059, 783986, 278229, 358302, 105038...  \n",
       "4           [272903, 278229, 405433, 399001, 494318]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Build Vocabulary\n",
    "vocab = set()\n",
    "for text in df['cleaned_text']:\n",
    "    words = text.split()\n",
    "    vocab.update(words)\n",
    "\n",
    "# Step 2: Create Word-to-Integer Mapping\n",
    "word_to_int = {word: idx for idx, word in enumerate(vocab, start=1)}\n",
    "\n",
    "# Step 3: Encode Text Data\n",
    "def encode_text(text):\n",
    "    words = text.split()\n",
    "    return [word_to_int[word] for word in words]\n",
    "\n",
    "# Apply encoding to the \"cleaned_text\" column\n",
    "df['encoded_text'] = df['cleaned_text'].apply(encode_text)\n",
    "\n",
    "# Display the first few rows of the DataFrame with encoded text\n",
    "df[['cleaned_text', 'encoded_text']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1f108f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the DataFrame: (1599999, 5)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of the DataFrame\n",
    "shape = df.shape\n",
    "\n",
    "# Display the shape\n",
    "print(\"Shape of the DataFrame:\", shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8582200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>encoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, Faceb...</td>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "      <td>[169960, 496697, 385662, 748809, 277102, 50188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[Kenichan, I, dived, many, times, for, the, ba...</td>\n",
       "      <td>Kenichan I dived many times for the ball Manag...</td>\n",
       "      <td>[465336, 850475, 629033, 513059, 8598, 601250,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[842064, 399001, 365467, 536171, 508846, 17586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[75233, 565059, 783986, 278229, 358302, 105038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>[Kwesidei, not, the, whole, crew]</td>\n",
       "      <td>Kwesidei not the whole crew</td>\n",
       "      <td>[272903, 278229, 405433, 399001, 494318]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  is upset that he can't update his Facebook by ...   \n",
       "1       0  @Kenichan I dived many times for the ball. Man...   \n",
       "2       0    my whole body feels itchy and like its on fire    \n",
       "3       0  @nationwideclass no, it's not behaving at all....   \n",
       "4       0                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [is, upset, that, he, cant, update, his, Faceb...   \n",
       "1  [Kenichan, I, dived, many, times, for, the, ba...   \n",
       "2  [my, whole, body, feels, itchy, and, like, its...   \n",
       "3  [nationwideclass, no, its, not, behaving, at, ...   \n",
       "4                  [Kwesidei, not, the, whole, crew]   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  is upset that he cant update his Facebook by t...   \n",
       "1  Kenichan I dived many times for the ball Manag...   \n",
       "2     my whole body feels itchy and like its on fire   \n",
       "3  nationwideclass no its not behaving at all im ...   \n",
       "4                        Kwesidei not the whole crew   \n",
       "\n",
       "                                        encoded_text  \n",
       "0  [169960, 496697, 385662, 748809, 277102, 50188...  \n",
       "1  [465336, 850475, 629033, 513059, 8598, 601250,...  \n",
       "2  [842064, 399001, 365467, 536171, 508846, 17586...  \n",
       "3  [75233, 565059, 783986, 278229, 358302, 105038...  \n",
       "4           [272903, 278229, 405433, 399001, 494318]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8fe522",
   "metadata": {},
   "source": [
    "As one can see now we have a dataframe containing all the necessary columns. Although we only require target and encoded _text column for our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f985b2",
   "metadata": {},
   "source": [
    "Let's print out the number of unique words in the vocabulary and the contents of the first, tokenized review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd01f573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words in Vocabulary: 866643\n",
      "\n",
      "Contents of the First Tokenized Review:\n",
      "[169960, 496697, 385662, 748809, 277102, 501888, 230632, 265518, 625889, 169354, 336286, 175867, 534648, 118990, 111446, 539740, 860909, 332527, 157890, 576326, 93424]\n"
     ]
    }
   ],
   "source": [
    "# Get the number of unique words in the vocabulary\n",
    "num_unique_words = len(vocab)\n",
    "\n",
    "# Get the contents of the first tokenized review\n",
    "first_tokenized_review = df['encoded_text'][0]\n",
    "\n",
    "# Print the results\n",
    "print(\"Number of Unique Words in Vocabulary:\", num_unique_words)\n",
    "print(\"\\nContents of the First Tokenized Review:\")\n",
    "print(first_tokenized_review)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7974b5fc",
   "metadata": {},
   "source": [
    "To check the maximum review text data length, we can iterate through the encoded text in our DataFrame and find the length of each encoded review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1737192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Review Text Length: 41\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum review text length\n",
    "max_length = max(len(encoded_text) for encoded_text in df['encoded_text'])\n",
    "\n",
    "# Print the maximum review text length\n",
    "print(\"Maximum Review Text Length:\", max_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a1b6fc",
   "metadata": {},
   "source": [
    "For shortest review,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86cbbcb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortest Review Text Length: 1\n"
     ]
    }
   ],
   "source": [
    "# Find the shortest review text length\n",
    "min_length = min(len(encoded_text) for encoded_text in df['encoded_text'])\n",
    "\n",
    "# Print the shortest review text length\n",
    "print(\"Shortest Review Text Length:\", min_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd7d94",
   "metadata": {},
   "source": [
    "The maximum and minimum review lengths are  41 and 1 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eca0ab0",
   "metadata": {},
   "source": [
    "Now we will so **padding** to ensure equal length of all reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4224bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>encoded_text</th>\n",
       "      <th>padded_encoded_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>[is, upset, that, he, cant, update, his, Faceb...</td>\n",
       "      <td>is upset that he cant update his Facebook by t...</td>\n",
       "      <td>[169960, 496697, 385662, 748809, 277102, 50188...</td>\n",
       "      <td>[169960, 496697, 385662, 748809, 277102, 50188...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>[Kenichan, I, dived, many, times, for, the, ba...</td>\n",
       "      <td>Kenichan I dived many times for the ball Manag...</td>\n",
       "      <td>[465336, 850475, 629033, 513059, 8598, 601250,...</td>\n",
       "      <td>[465336, 850475, 629033, 513059, 8598, 601250,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[my, whole, body, feels, itchy, and, like, its...</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>[842064, 399001, 365467, 536171, 508846, 17586...</td>\n",
       "      <td>[842064, 399001, 365467, 536171, 508846, 17586...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>[nationwideclass, no, its, not, behaving, at, ...</td>\n",
       "      <td>nationwideclass no its not behaving at all im ...</td>\n",
       "      <td>[75233, 565059, 783986, 278229, 358302, 105038...</td>\n",
       "      <td>[75233, 565059, 783986, 278229, 358302, 105038...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "      <td>[Kwesidei, not, the, whole, crew]</td>\n",
       "      <td>Kwesidei not the whole crew</td>\n",
       "      <td>[272903, 278229, 405433, 399001, 494318]</td>\n",
       "      <td>[272903, 278229, 405433, 399001, 494318, 0, 0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text  \\\n",
       "0       0  is upset that he can't update his Facebook by ...   \n",
       "1       0  @Kenichan I dived many times for the ball. Man...   \n",
       "2       0    my whole body feels itchy and like its on fire    \n",
       "3       0  @nationwideclass no, it's not behaving at all....   \n",
       "4       0                      @Kwesidei not the whole crew    \n",
       "\n",
       "                                      processed_text  \\\n",
       "0  [is, upset, that, he, cant, update, his, Faceb...   \n",
       "1  [Kenichan, I, dived, many, times, for, the, ba...   \n",
       "2  [my, whole, body, feels, itchy, and, like, its...   \n",
       "3  [nationwideclass, no, its, not, behaving, at, ...   \n",
       "4                  [Kwesidei, not, the, whole, crew]   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  is upset that he cant update his Facebook by t...   \n",
       "1  Kenichan I dived many times for the ball Manag...   \n",
       "2     my whole body feels itchy and like its on fire   \n",
       "3  nationwideclass no its not behaving at all im ...   \n",
       "4                        Kwesidei not the whole crew   \n",
       "\n",
       "                                        encoded_text  \\\n",
       "0  [169960, 496697, 385662, 748809, 277102, 50188...   \n",
       "1  [465336, 850475, 629033, 513059, 8598, 601250,...   \n",
       "2  [842064, 399001, 365467, 536171, 508846, 17586...   \n",
       "3  [75233, 565059, 783986, 278229, 358302, 105038...   \n",
       "4           [272903, 278229, 405433, 399001, 494318]   \n",
       "\n",
       "                                 padded_encoded_text  \n",
       "0  [169960, 496697, 385662, 748809, 277102, 50188...  \n",
       "1  [465336, 850475, 629033, 513059, 8598, 601250,...  \n",
       "2  [842064, 399001, 365467, 536171, 508846, 17586...  \n",
       "3  [75233, 565059, 783986, 278229, 358302, 105038...  \n",
       "4  [272903, 278229, 405433, 399001, 494318, 0, 0,...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define the maximum sequence length based on your data\n",
    "max_sequence_length = 41  # Set it to the maximum review length in your data\n",
    "\n",
    "# Pad the sequences in the encoded_text column\n",
    "df['padded_encoded_text'] = pad_sequences(df['encoded_text'], maxlen=max_sequence_length, padding='post', truncating='post', value=0).tolist()\n",
    "\n",
    "# Display the DataFrame with the padded sequences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bd6102c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Sequence 1:\n",
      "[169960, 496697, 385662, 748809, 277102, 501888, 230632, 265518, 625889, 169354, 336286, 175867, 534648, 118990, 111446, 539740, 860909, 332527, 157890, 576326, 93424, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "Padded Sequence 2:\n",
      "[465336, 850475, 629033, 513059, 8598, 601250, 405433, 559327, 844639, 650431, 251900, 315576, 42770, 655162, 401707, 463699, 631581, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "Padded Sequence 3:\n",
      "[842064, 399001, 365467, 536171, 508846, 175867, 701103, 783986, 491374, 310925, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "Padded Sequence 4:\n",
      "[75233, 565059, 783986, 278229, 358302, 105038, 354659, 828923, 411971, 111687, 732349, 551620, 225241, 172544, 850475, 277102, 200567, 731448, 354659, 416935, 176657, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n",
      "Padded Sequence 5:\n",
      "[272903, 278229, 405433, 399001, 494318, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "padded_sequences = df['padded_encoded_text'].values\n",
    "\n",
    "# Loop through the first few rows and print the padded sequences\n",
    "for i in range(5):  # Displaying the first 5 rows for example\n",
    "    print(f\"Padded Sequence {i + 1}:\")\n",
    "    print(padded_sequences[i])\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f445c",
   "metadata": {},
   "source": [
    "Now we will split the data for Train, Test and Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cced19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features (X) and target (y)\n",
    "X = df['padded_encoded_text'].tolist()\n",
    "y = df['target'].tolist()\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8095bba5",
   "metadata": {},
   "source": [
    "Now we have X_train, y_train for training, X_val, y_val for validation, and X_test, y_test for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "825b164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 9430/20000 [=============>................] - ETA: 2:15:25 - loss: -310.1271 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5796/3055123543.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m# Evaluate the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1562\u001b[0m                         ):\n\u001b[0;32m   1563\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1564\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1565\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1566\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       (graph_function,\n\u001b[0;32m   2495\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2497\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1860\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1861\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1862\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1863\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1864\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "embedding_dim = 100\n",
    "# Define your model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_unique_words, output_dim=embedding_dim, input_length=max_sequence_length))\n",
    "model.add(LSTM(64, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0ba81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
